{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g1lzjW5NJNT"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"yashikota/birds-525-species-image-classification\")\n",
        "print(ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from PIL import Image\n",
        "df = pd.DataFrame(ds['train'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "pYRt3PwXfv03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "for x in ds['train'].shuffle(seed=231).select(range(5)):\n",
        "  display(x[\"image\"])\n",
        "  print(\"Label: \", ds['train'].features['label'].int2str(x['label']))"
      ],
      "metadata": {
        "id": "NRf_xO1igqY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking Label and Image for an American Wigeon\n",
        "display(ds[\"train\"][3924][\"image\"])\n",
        "display(ds['train'].features[\"label\"].int2str(ds['train'][3924]['label']))"
      ],
      "metadata": {
        "id": "tRwkDSr_QhZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying Features to see our classes\n",
        "display(ds['train'].features)"
      ],
      "metadata": {
        "id": "TpaaGdaLQ7sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for corrupted images by image link is None\n",
        "bad_images = []\n",
        "\n",
        "for i in range(len(ds['train'])):\n",
        "  image = ds['train'][i]['image']\n",
        "  if image is None:\n",
        "    bad_images.append(i)\n",
        "\n",
        "print(f\"Total number of corrupt/null images: {len(bad_images)}\")\n",
        "print(\"First Bad Ones: \", bad_images[:25])"
      ],
      "metadata": {
        "id": "Wj6M7PZyhKLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for bird images that are not the same size as the defaulted 224x224\n",
        "size_unmatched = []\n",
        "for i in range(len(ds['train'])):\n",
        "  width, height = ds['train'][i]['image'].size\n",
        "  if width != 224 or height != 224:\n",
        "    size_unmatched.append(i)\n",
        "print(f\"Amount of images not 224x224:{len(size_unmatched)}\")\n",
        "print(size_unmatched[:20])"
      ],
      "metadata": {
        "id": "TYzDEua5kgxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Understanding size differences by checking a few of the images not our default size\n",
        "for idx in size_unmatched[:10]:\n",
        "  display(ds['train'][idx]['image'])"
      ],
      "metadata": {
        "id": "oKXuyooQklS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "e30OQTYqk6YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_image = ds['train'][0]['image']\n",
        "\n",
        "display(first_image)\n",
        "\n",
        "image_size = first_image.size\n",
        "print(f\"Image size (width, height): {image_size}\")\n",
        "\n",
        "image_format = first_image.format\n",
        "print(f\"Image format: {image_format}\")\n",
        "\n",
        "image_mode = first_image.mode\n",
        "print(f\"Image mode: {image_mode}\")"
      ],
      "metadata": {
        "id": "vKwoFfz2lzVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = ResNet18_Weights.DEFAULT\n",
        "model = models.resnet18(weights=weights)\n",
        "model.fc = torch.nn.Identity()\n",
        "model.eval()\n",
        "transform = weights.transforms()\n",
        "\n",
        "def get_embedding(img):\n",
        " x = transform(img).unsqueeze(0)\n",
        " with torch.no_grad():\n",
        "    emb = model(x).squeeze().numpy()\n",
        " return emb"
      ],
      "metadata": {
        "id": "zxVHKc0Pl2gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "image1 = ds['train'][0]['image']\n",
        "image2 = ds['train'][3]['image']\n",
        "\n",
        "print(\"Image 1:\")\n",
        "display(image1)\n",
        "print(\"\\nImage 2:\")\n",
        "display(image2)\n",
        "\n",
        "\n",
        "img1 = get_embedding(image1)\n",
        "img2 = get_embedding(image2)\n",
        "\n",
        "\n",
        "img1 = img1.reshape(1, -1)\n",
        "img2 = img2.reshape(1, -1)\n",
        "\n",
        "similarity = cosine_similarity(img1, img2)[0][0]\n",
        "\n",
        "print(f\"\\nSimilarity between the first two images: {similarity}\")\n",
        "\n",
        "if similarity > 0.90:\n",
        "    print(\"duplicates\")\n",
        "else:\n",
        "    print(\"not duplicates.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "CQTSmWltl47t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#class imbalances\n",
        "#making a dictionary of species names and how many pictures there are of each species to filter through later\n",
        "#only done for training data since we are just training the model\n",
        "\n",
        "#print(ds['train'].features) #dictionary of names from the label\n",
        "from collections import Counter #counts how many there are of each label\n",
        "values=ds[\"train\"][\"label\"]\n",
        "counts=Counter(values)\n",
        "#print(counts) #how much there are of each value, key associated with a certain species\n",
        "labels=ds[\"train\"].features[\"label\"].names #getting the species names\n",
        "countsSpecies={labels[i]: c for i, c in counts.items()} #makes a dictionary of the species and how many images there are in alphabetical order\n",
        "#print(countsSpecies)"
      ],
      "metadata": {
        "id": "AAcC_H5Wzv01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assigning weights to different classes, best for datasets with medium levels of imbalance (eg. here)\n",
        "#using cross entropy to have the model weigh classes with less samples more\n",
        "#undersampling is not preferred due to the risk of permanently removing important data from the dataset\n",
        "\n",
        "#for PyTorch\n",
        "import torch\n",
        "\n",
        "classCounts=torch.tensor([counts[i] for i in range(len(labels))], dtype=torch.float) #creates a list of how many there are per species alphabetically\n",
        "\n",
        "n=classCounts.sum() #formula for computing the class weights\n",
        "c=len(classCounts)\n",
        "classWeights=n/(c*classCounts)\n",
        "#print(classWeights)"
      ],
      "metadata": {
        "id": "DJZIe-9pz1uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the loss function with these weights to properly evaluate the accuracy after training\n",
        "import torch.nn as nn\n",
        "criterion=nn.CrossEntropyLoss(weight=classWeights)\n",
        "#all of the above goes before creating the model and training it\n",
        "#with this, running the loss function weighs mistakes more heavily on the species with less pictures than speices with more pictures"
      ],
      "metadata": {
        "id": "mKGotoG0z4DX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}